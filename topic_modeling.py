# -*- coding: utf-8 -*-
"""Topic Modeling.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1M87SMsacITkJ5M20g8sSNZOe2LpRtb_b
"""

import pandas as pd
import numpy as np
from sklearn.pipeline import Pipeline

# to display all columns and rows:
pd.set_option('display.max_columns', None); pd.set_option('display.max_rows', None);
pd.set_option('display.max_colwidth', None);
#to arrange the decimals
pd.set_option('display.float_format', lambda x: '%.3f' % x)

# First lets connect the Gdrive that contains the data
from google.colab import drive
drive.mount('/content/drive', force_remount=True)

import os
# The path below should point to the directory containing this notebook and the associated utility files
# Change it if necessary
os.chdir('/content/drive/MyDrive/MLOps-Nov21')
!ls

model = pd.read_csv('Model.csv')

validation = pd.read_csv('validation.csv')

model.head()

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import NMF

train = tfidf.fit_transform(model['Consumer_complaint'])

test = tfidf.transform(validation['Consumer_complaint'])

nmf_model = NMF(n_components=5,random_state=42)

nmf_model.fit(train)

len(tfidf.get_feature_names())

for index,topic in enumerate(nmf_model.components_):
    print(f'THE TOP 15 WORDS FOR TOPIC #{index}')
    print([tfidf.get_feature_names()[i] for i in topic.argsort()[-15:]])
    print('\n')

topic_results = nmf_model.transform(train)

topic_results_test = nmf_model.transform(test)

model['Topic'] = topic_results.argmax(axis = 1)

validation['Topic'] = topic_results_test.argmax(axis = 1)

mytopic_dict = {0: 'credit repair', 1: 'rewards', 2: 'debt settlement', 3: 'fees', 4: 'digital wallet'}

model['Topic Label'] = model['Topic'].map(mytopic_dict)

validation['Topic Label'] =validation['Topic'].map(mytopic_dict)

import pickle
filename = 'final_model.sav'
pickle.dump(nmf_model, open(filename, 'wb'))